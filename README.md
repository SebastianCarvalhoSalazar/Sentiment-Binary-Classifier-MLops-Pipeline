# ðŸŽ¬ Movie Sentiment MLOps

Un proyecto completo de MLOps para clasificaciÃ³n de sentimientos en reseÃ±as de pelÃ­culas con pipeline de reentrenamiento automÃ¡tico.

## CaracterÃ­sticas

- **Machine Learning**: ClasificaciÃ³n de sentimientos usando TF-IDF con mÃºltiples modelos (Logistic Regression, Random Forest, XGBoost)
- **OptimizaciÃ³n Bayesiana**: BÃºsqueda inteligente de hiperparÃ¡metros con scikit-optimize
- **MLflow**: Tracking de experimentos y registro de modelos
- **FastAPI**: API REST para servir predicciones
- **Streamlit**: Interfaz web interactiva
- **Monitoreo de Drift**: DetecciÃ³n automÃ¡tica de drift con Evidently
- **Pipeline Automatizado**: Reentrenamiento automÃ¡tico con Apache Airflow
- **Docker**: ContainerizaciÃ³n de todos los servicios
- **Testing**: Suite de pruebas con pytest

## Quick Start

### OpciÃ³n 1: EjecuciÃ³n Local

1. **Clonar el repositorio**
```bash
git clone <tu-repositorio>
cd movie-sentiment-mlops
```

2. **Crear ambiente virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
pip install Flask-Session==0.5.0  # Para Airflow
```

4. **Entrenar el modelo inicial**
```bash
# OpciÃ³n 1: Entrenamiento bÃ¡sico
python src/train.py --model logistic_regression

# OpciÃ³n 2: Con optimizaciÃ³n bayesiana (recomendado)
python src/train_bayesian.py --model xgboost

# OpciÃ³n 3: Comparar mÃºltiples modelos
python src/train_bayesian.py --model compare
```

5. **Configurar monitoreo**
```bash
# Crear datos de referencia para detecciÃ³n de drift
python monitoring/setup_monitoring.py
```

6. **Iniciar MLflow UI** (opcional)
```bash
mlflow ui
# Abrir http://localhost:5000
```

7. **Iniciar la API**
```bash
python app/api.py
# API disponible en http://localhost:8000
# DocumentaciÃ³n en http://localhost:8000/docs
```

8. **Iniciar Streamlit**
```bash
streamlit run app/streamlit_app.py
# Abrir http://localhost:8501
```

### OpciÃ³n 2: Usando Docker Compose

```bash
# Construir y ejecutar todos los servicios base
docker-compose up --build

# Servicios disponibles:
# - MLflow: http://localhost:5000
# - API: http://localhost:8000/docs
# - Streamlit: http://localhost:8501
```

## ðŸ”„ Pipeline de Reentrenamiento AutomÃ¡tico (Airflow)

### ConfiguraciÃ³n Inicial

1. **Instalar Apache Airflow**
```bash
pip install apache-airflow==2.7.3
pip install Flask-Session==0.5.0  # Dependencia necesaria
```

2. **Configurar Airflow**
```bash
# Hacer el script ejecutable
chmod +x setup_airflow.sh

# Ejecutar configuraciÃ³n
./setup_airflow.sh
```

3. **Iniciar Airflow**
```bash
# OpciÃ³n 1: Modo standalone (mÃ¡s simple)
export AIRFLOW_HOME=$(pwd)/airflow
export AIRFLOW_HOME=$(pwd)/airflowexport AIRFLOW_HOME=$(pwd)/airflow
# OpciÃ³n 2: Servicios separados
# Terminal 1 - Scheduler:
export AIRFLOW_HOME=$(pwd)/airflow
airflow scheduler

# Terminal 2 - Webserver:
export AIRFLOW_HOME=$(pwd)/airflow
airflow webserver --port 8080
```

4. **Acceder a Airflow UI**
- URL: http://localhost:8080
- Usuario: admin
- Password: (se muestra en la terminal o usar 'admin' si configuraste manualmente)

### Pipeline Automatizado

El pipeline ejecuta automÃ¡ticamente las siguientes tareas:

```mermaid
graph LR
    A[Verificar Drift] -->|Drift Detectado| B[Reentrenar Modelo]
    A -->|Sin Drift| C[Skip]
    B --> D[Comparar Modelos]
    D -->|Mejor| E[Promover a ProducciÃ³n]
    D -->|Peor| F[Mantener Actual]
    C --> G[Notificar]
    E --> G
    F --> G
```

**CaracterÃ­sticas del Pipeline:**
- **Monitoreo Diario**: Verifica drift en las distribuciones de datos
- **Reentrenamiento Condicional**: Solo entrena si detecta drift significativo
- **EvaluaciÃ³n AutomÃ¡tica**: Compara nuevo modelo vs producciÃ³n
- **PromociÃ³n Inteligente**: Solo promueve si mejora mÃ©tricas (F1-score)
- **Trazabilidad**: Logs completos y notificaciones de cada paso

### Probar el Pipeline

```bash
# Test manual del monitoreo de drift
python monitoring/drift_monitor.py --airflow

# Test completo del DAG
export AIRFLOW_HOME=$(pwd)/airflow
airflow dags test movie_sentiment_retrain $(date +%Y-%m-%d)

# Ver logs
tail -f airflow/logs/dag_id=movie_sentiment_retrain/run_id=*/task_id=*/*.log
```

## Estructura del Proyecto

```
movie-sentiment-mlops/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py                 # API REST con FastAPI
â”‚   â””â”€â”€ streamlit_app.py       # Interfaz web
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py              # Entrenamiento bÃ¡sico
â”‚   â”œâ”€â”€ train_bayesian.py     # Entrenamiento con optimizaciÃ³n
â”‚   â”œâ”€â”€ model_comparator.py   # ComparaciÃ³n de modelos
â”‚   â””â”€â”€ utils.py              # Utilidades compartidas
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ drift_monitor.py      # Monitor de drift con Evidently
â”‚   â””â”€â”€ setup_monitoring.py   # ConfiguraciÃ³n inicial
â”œâ”€â”€ airflow/                  # Directorio de Airflow (generado)
â”‚   â”œâ”€â”€ dags/                # DAGs de Airflow
â”‚   â”œâ”€â”€ logs/                # Logs de ejecuciÃ³n
â”‚   â””â”€â”€ airflow.db           # Base de datos SQLite
â”œâ”€â”€ data/                     # Datasets
â”œâ”€â”€ models/                   # Modelos entrenados
â”‚   â”œâ”€â”€ production.pkl       # Modelo en producciÃ³n
â”‚   â””â”€â”€ *.pkl               # Otros modelos
â”œâ”€â”€ mlruns/                  # Experimentos MLflow
â”œâ”€â”€ monitoring_data/         # Datos de monitoreo
â”‚   â”œâ”€â”€ reference_data.parquet
â”‚   â”œâ”€â”€ drift_report_*.html
â”‚   â””â”€â”€ airflow/           # Resultados para Airflow
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py         # Tests unitarios
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile              # Imagen Docker base
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ setup_airflow.sh       # Script configuraciÃ³n Airflow
â”œâ”€â”€ .env                   # Variables de entorno
â””â”€â”€ README.md             # Este archivo
```

## API Endpoints

### PredicciÃ³n Simple
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"text": "This movie was amazing!"}'
```

### PredicciÃ³n por Lotes
```bash
curl -X POST "http://localhost:8000/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{"reviews": ["Great movie!", "Terrible film."]}'
```

### Health Check
```bash
curl "http://localhost:8000/health"
```

### Reload Model
```bash
curl -X POST "http://localhost:8000/reload-model"
```

## Monitoreo y MÃ©tricas

### MLflow
- Experimentos: http://localhost:5000
- Tracking de mÃ©tricas: accuracy, precision, recall, F1
- Versionado de modelos
- ComparaciÃ³n de runs

### Evidently (Drift Monitoring)
- DetecciÃ³n de drift en distribuciones
- MÃ©tricas de calibraciÃ³n (ECE)
- Reportes HTML interactivos
- Alertas automÃ¡ticas

### MÃ©tricas Monitoreadas
- **Data Drift**: Cambios en distribuciÃ³n de features
- **Prediction Drift**: Cambios en distribuciÃ³n de predicciones
- **Confidence Drift**: Cambios en confianza del modelo
- **Performance**: F1, Accuracy, Precision, Recall

## Testing

```bash
# Ejecutar todos los tests
pytest tests/

# Con cobertura
pytest --cov=src tests/

# Tests especÃ­ficos
pytest tests/test_api.py -v

# Ignorar warnings
pytest -W ignore tests/
```

## ConfiguraciÃ³n

Variables de entorno en `.env`:
```bash
# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000
MODEL_NAME=movie_sentiment_classifier
MODEL_STAGE=Production

# API
API_HOST=0.0.0.0
API_PORT=8000

# Monitoring
DRIFT_THRESHOLD=0.15

# Airflow
AIRFLOW_HOME=./airflow
```

## Troubleshooting

### Problema: ModuleNotFoundError en Airflow
```bash
# SoluciÃ³n:
pip install Flask-Session==0.5.0
```

### Problema: DAG no aparece en Airflow UI
```bash
# Verificar logs
cat $AIRFLOW_HOME/logs/scheduler/*.log

# Reiniciar scheduler
kill -9 $(lsof -t -i :8080)
pkill -f "airflow scheduler"
airflow scheduler
```

### Problema: Error de permisos
```bash
# Dar permisos de ejecuciÃ³n
chmod +x setup_airflow.sh
chmod -R 755 airflow/
```

### Problema: Puerto en uso
```bash
# Verificar procesos
lsof -i :8080  # Airflow
lsof -i :8000  # FastAPI
lsof -i :5000  # MLflow

# Terminar proceso
kill -9 $(lsof -ti :8080)
```

## PrÃ³ximos Pasos

### Mejoras Inmediatas
- [ ] Implementar cachÃ© con Redis
- [ ] Agregar autenticaciÃ³n JWT a la API
- [ ] Configurar alertas por email/Slack
- [ ] Implementar data versioning con DVC

### Mejoras Avanzadas
- [ ] Migrar a Kubernetes para escalabilidad
- [ ] Implementar A/B testing
- [ ] Feature store con Feast
- [ ] CI/CD con GitHub Actions
- [ ] Observabilidad con Prometheus/Grafana

## Recursos y DocumentaciÃ³n

- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [MLflow Guide](https://mlflow.org/docs/latest/index.html)
- [Airflow Documentation](https://airflow.apache.org/docs/)
- [Evidently AI](https://docs.evidentlyai.com/)
- [Streamlit Docs](https://docs.streamlit.io/)

## Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.

---

## Nota Importante sobre el Reentrenamiento AutomÃ¡tico
El pipeline de reentrenamiento automÃ¡tico implementado en este proyecto detecta exitosamente el drift en los datos de producciÃ³n y ejecuta el proceso de reentrenamiento; sin embargo, es crucial entender que en su estado actual, el sistema reentrena utilizando los mismos datos originales del dataset IMDB debido a una limitaciÃ³n fundamental: los datos de producciÃ³n que causan el drift no vienen etiquetados. En un escenario real de producciÃ³n, este enfoque serÃ­a inefectivo ya que no resolverÃ­a el problema del drift. Para implementar un reentrenamiento verdaderamente Ãºtil, serÃ­a necesario primero establecer un mecanismo de obtenciÃ³n de etiquetas para los nuevos datos, como: un sistema de feedback donde usuarios validen predicciones, un proceso de etiquetado manual periÃ³dico o active learning para priorizar quÃ© ejemplos etiquetar. Este proyecto demuestra la infraestructura y arquitectura MLOps necesaria para el reentrenamiento automÃ¡tico, pero en aplicaciones reales, resolver el problema del etiquetado continuo es prerequisito para que el pipeline genere valor real. El reentrenamiento actual sirve principalmente como demostraciÃ³n tÃ©cnica del flujo completo de MLOps, desde la detecciÃ³n de drift hasta la promociÃ³n de modelos, pero no mejorarÃ¡ el rendimiento del modelo en los nuevos patrones de datos detectados.

## Mejora Recomendada: PromociÃ³n de Modelos con MLflow Registry
Actualmente la promociÃ³n de modelos se realiza copiando archivos .pkl directamente, lo cual es funcional pero carece de versionado y trazabilidad. Se recomienda migrar al MLflow Model Registry que ya estÃ¡ instalado en el proyecto, permitiendo transiciones controladas entre estados (Experimental â†’ Staging â†’ Production), versionado semÃ¡ntico, metadata detallada de cada modelo, y rollback instantÃ¡neo si falla en producciÃ³n. La implementaciÃ³n requerirÃ­a modificar train_bayesian.py para registrar modelos con mlflow.register_model(), actualizar model_comparator.py para usar client.transition_model_version_stage() al promover, y cambiar api.py para cargar desde el registry con mlflow.pyfunc.load_model("models:/movie_sentiment_classifier/Production").

---

**Desarrollado para aprender MLOps end-to-end** 
**Desde el entrenamiento hasta producciÃ³n con monitoreo y reentrenamiento automÃ¡tico.

